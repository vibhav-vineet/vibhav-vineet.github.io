
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Vibhav Vineet"> 
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Vibhav Vineet</title>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
</script>
</head>

<body>


<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#index">Home</a>
        <a href="publication.html">Publication</a>
        <a href="interns.html">Interns</a>
    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                <h1>Vibhav Vineet</h1>
        </div>
        <p>
          Principal Researcher <!-- in <a href="https://www.microsoft.com/en-us/research/group/vision/"> Computer Vision Group </a> --> </br> 
          <!-- Affiliated to <a href="https://www.microsoft.com/en-us/research/group/robot-learning-group/"> Robot Learning Group </a> </br> -->
          Microsoft Research</br>
          Redmond, WA</br>
          Email: firstname[dot]lastname[at]microsoft[dot]com</br>
        
        </p>
        <p>
          <a href="http://scholar.google.com/citations?user=E_UlAVQAAAAJ&hl=en">Google Scholar </a> , &nbsp
          <a href="http://dblp.uni-trier.de/pers/hd/v/Vineet:Vibhav"> DBLP </a>
        </p>
      </td>
      <td><img src="images/vibhav.png" border="0" height="250"></br></td>
    <tr>
  </tbody>
</table>

<h2>Research</h2>
<p>
  <div style="text-align:justify">My research interests are in computer vision, machine learning, and human-AI interactions. My ongoing research is focused on the development of models that utilize multi-modal data to enhance AI systems' ability to perceive and reason about the real-world environments of human users. This advancement will ultimately help AI systems to seamlessly interact and collaborate with humans, accomplishing tasks within the real world efficiently. <br>
	  Topics of interest. 1) Multi-modal robustness analysis and reasoning. 2) Video understanding and generation. 3) Synthetic data for computer vision and AI models. 4) Embodied AI.

<br> <br>

<em> <strong>If you are interested in research collaborations or doing research internship at MSR Redmond, please contact me. </strong> </em>

  </div>
</p>



<div id="Recent and Selected Publications">
<h2>Recent and Selected Publications </h2>

<ul>
  <li> <a href="https://arxiv.org/pdf/2504.21318?">Phi-4-reasoning technical report</a>, ArXiv 2025<br> </li>
  <li> <a href="https://arxiv.org/pdf/2504.00294">Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead</a>, ArXiv 2025<br> </li>
  <li> <a href="https://arxiv.org/pdf/2503.08585?">HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding</a>, CVPR 2025<br> </li>
  <li> <a href="https://arxiv.org/pdf/2410.13826">Unearthing Skill-Level Insights For Under Sstanding Trade-Offs Of Foundation Models</a>, ICLR 2025<br> </li>
  <li> <a href="https://arxiv.org/pdf/2312.14216">DreamDistribution: Prompt Distribution Learning for Text-to-Image Diffusion Models</a>, ICLR 2025<br> </li>
	<li> <a href="https://arxiv.org/pdf/2501.04155?">MM-GEN: Enhancing Task Performance Through Targeted Multimodal Data Curation</a>, ArXiv 2025<br> </li>  
  <li> <a href="https://arxiv.org/pdf/2305.18583">Controllable Text-to-Image Generation with GPT-4</a>, ArXiv 2023<br> </li>
  <li> <a href="https://arxiv.org/pdf/2106.03805">3db: A framework for debugging computer vision models</a>, NeurIPS 2022<br> </li>
  <li> <a href="https://arxiv.org/pdf/2207.11368">Neural-Sim: Learning to Generate Training Data with NeRF</a>, ECCV 2022<br> </li>      
  <li> <a href="https://arxiv.org/pdf/2212.10015">Benchmarking Spatial Reasoning Abilities of Text-to-Image Generative Models</a>, ArXiv 2022<br> </li>
  <li> <a href="https://arxiv.org/pdf/2206.09592">DALL-E for Detection: Language-driven Context Image Synthesis for Object Detection</a>, ArXiv 2022<br> </li>
  <li> <a href="https://arxiv.org/pdf/2203.10488.pdf">Inferring Articulated Rigid Body Dynamics from RGBD Video</a>, IROS 2022<br> </li>
  <li> <a href="https://arxiv.org/pdf/2008.08424">AutoSimulate:(Quickly) Learning Synthetic Data Generation</a>, ECCV 2020<br> </li>
  <li> <a href="https://arxiv.org/pdf/1608.02192">Playing for data: Ground truth from computer games</a>, ECCV 2016<br> </li>
  <li> <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Feature space optimization for semantic video segmentation</a>, CVPR 2016<br> </li>
  <li> <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: Interactive 3d labeling and learning at your fingertips</a>, ACM TOG 2015<br> </li>
  <li> <a href="">The semantic paintbrush: Interactive 3d mapping and recognition in large outdoor spaces</a>, CHI 2015<br> </li>
</ul>

<div id="Videos">
<h2>Videos </h2>

<ul>
  <li> <a href="https://www.youtube.com/watch?v=g7edzB7qo98">VideoSim</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=gCCVwE3vI-E">Reconstruction of Dynamic Outdoor Scenes</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=JGAIfWG2MQQ&t=2s">Playing for Data</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=Ay0bcHd0B6c">Semantic Video Segmentation</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=576wabD70hM">Semantic Paint</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=IDsE9jjF5h0">Semantic Paint Supplementary</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=teQOLFQ-HLE">Semantic Paint Brush</a> </li>
  <li> <a href="https://www.youtube.com/watch?v=uhDVLKy9YJs">Incremental Dense Semantic Scene Reconstruction</a> </li>
</ul>


<div id="Code & Models">
<h2>Code & Dataset</h2>

<ul>
  <li> <a href="https://huggingface.co/microsoft/Phi-4-reasoning">Phi-4-reasoning technical report</a><br> </li>
  <li> <a href="https://github.com/microsoft/eureka-ml-insights">Eureka</a><br> </li>
  <li> <a href="https://github.com/microsoft/skill-slice-insights">Skill Slice Insights</a><br> </li>
  <li> <a href="https://github.com/jiayuww/SpatialEval">SpatialEval</a><br> </li>
  <li> <a href="https://github.com/microsoft/Peekaboo">Peekaboo</a><br> </li>
  <li> <a href="https://github.com/jinga-lala/DAMEX">DAMEX</a><br> </li>
  <li> <a href="https://shroglck.github.io/rev_unseen/">Benchmarking video action recognition under occlusion</a><br> </li>
  <li> <a href="https://github.com/rajatmodi62/OccludedActionBenchmark">Benchmarking video action detection under occlusion</a><br> </li>
  <li> <a href="https://github.com/DeepLearningRobustnessStudies/SegmetationRobustness">Robustness of Segmentation Models</a><br> </li>
  <li> <a href="https://github.com/SruthiSudhakar/Exploring-the-Sim2RealGap-using-Digital-Twins-Dataset">YCB Sim2Real Gap</a><br> </li>
  <li> <a href="https://github.com/tianjunz/Control-GPT">Control-GPT</a><br> </li>
  <li> <a href="https://github.com/gyhandy/Neural-Sim-NeRF">Neural-Sim</a><br> </li>
  <li> <a href="https://causalcity.github.io/">CausalCity</a><br> </li>
  <li> <a href="https://github.com/madrylab/missingness">Missingness Biasness</a><br> </li>
  <li> <a href="https://github.com/McGill-NLP/imagecode">ImageCoDe</a><br> </li>
  <li> <a href="https://eric-heiden.github.io/video2sim/">VideoSim</a><br> </li>
  <li> <a href="https://github.com/chingyaoc/RINCE">RINCE</a><br> </li>
  <li> <a href="https://github.com/weizheliu/VAVA">VAVA</a><br> </li>
  <li> <a href="https://github.com/3db/3db">3DB</a><br> </li>
  <li> <a href="https://github.com/microsoft/VISOR">VISOR</a><br> </li>
  <li> <a href="https://faculty.eng.ufl.edu/soundpad-lab/research/aml/">Acoustic Machine Learning</a><br> </li>
  <li> <a href="https://github.com/microsoft/AirSim-Drone-Racing-VAE-Imitation">Drone Racing</a><br> </li>
  <li> <a href="https://thodan.github.io/objectsynth/">ObjectSynth</a><br> </li>
  <li> <a href="https://download.visinf.tu-darmstadt.de/data/from_games/">Playing for Data</a><br> </li>
  <li> <a href="https://download.visinf.tu-darmstadt.de/data/from_games/">Playing for Data</a><br> </li>
</ul>


</ul>
</div>


<div id="footer">
  <div id="footer-text"></div>
</div>

	<center>Adapted from  <a href="https://hszhao.github.io/"> This page </a> | Last updated: 04/13/2025</center>

</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
