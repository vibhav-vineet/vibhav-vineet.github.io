
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Vibhav Vineet"> 
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Vibhav Vineet</title>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
</script>
</head>

<body>


<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#index">Home</a>
        <a href="publication.html">Publication</a>
        <a href="interns.html">Interns</a>
    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                <h1>Vibhav Vineet</h1>
        </div>
        <p>
          Principal Researcher <!-- in <a href="https://www.microsoft.com/en-us/research/group/vision/"> Computer Vision Group </a> --> </br> 
          <!-- Affiliated to <a href="https://www.microsoft.com/en-us/research/group/robot-learning-group/"> Robot Learning Group </a> </br> -->
          Microsoft Research</br>
          Redmond, WA</br>
          Email: firstname[dot]lastname[at]microsoft[dot]com</br>
        
        </p>
        <p>
          <a href="http://scholar.google.com/citations?user=E_UlAVQAAAAJ&hl=en">Google Scholar </a> , &nbsp
          <a href="http://dblp.uni-trier.de/pers/hd/v/Vineet:Vibhav"> DBLP </a>
        </p>
      </td>
      <td><img src="images/vibhav.png" border="0" height="250"></br></td>
    <tr>
  </tbody>
</table>

<h2>Research</h2>
<p>
  <div style="text-align:justify">My research interests are in computer vision, machine learning, and human-AI interactions. My ongoing research is focused on the development of models that utilize multi-modal data to enhance AI systems' ability to perceive and reason about the real-world environments of human users. This advancement will ultimately help AI systems to seamlessly interact and collaborate with humans, accomplishing tasks within the real world efficiently. <br>
	  Topics of interest. 1) Multi-modal robustness analysis and reasoning. 2) Video understanding and generation. 3) Synthetic data for computer vision and AI models. 4) Embodied AI.

<br> <br>

<em> <strong>If you are interested in research collaborations or doing research internship at MSR Redmond, please contact me. </strong> </em>

  </div>
</p>



<div id="Recent and Selected Publications">
<h2>Recent and Selected Publications </h2>


<ul>

  <li>
    <a href="https://arxiv.org/pdf/2504.21318?">Phi-4-reasoning technical report</a><br>
    <!--  Abdin, et.al., </b>.<br> -->
    <b>ArXiv</b>, 2025.</br>  
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2504.21318?">Paper</a>] [<a href="https://huggingface.co/microsoft/Phi-4-reasoning">HF model</a>] 
    </p>
  </li>

	   <li>
    <a href="https://arxiv.org/pdf/2504.00294">Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead</a><br>
    Vidhisha Balachandran, Jingya Chen, Lingjiao Chen, Shivam Garg, Neel Joshi, Yash Lara, John Langford, Besmira Nushi, Vibhav Vineet, Yue Wu, Safoora Yousefi </b>.<br>    
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2504.00294">Paper</a>] [<a href="https://github.com/microsoft/eureka-ml-insights">Eureka</a>]
    </p>
  </li>
  
     <li>
    <a href="https://arxiv.org/pdf/2503.08585?">HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding</a><br>
    Shehreen Azad, Vibhav Vineet, Yogesh Singh Rawat  </b>.<br>
    <em>Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2503.08585?">Paper</a>] [<a href="https://sacrcv.github.io/HierarQ-website/">Project Page</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2410.13826">Unearthing Skill-Level Insights For Under Sstanding Trade-Offs Of Foundation Models</a><br>
    Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet  </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2410.13826">Paper</a>] [<a href="https://github.com/microsoft/skill-slice-insights">Code & Dataset</a>]
    </p>
  </li>

    <li>
    <a href="https://arxiv.org/pdf/2312.14216">DreamDistribution: Prompt Distribution Learning for Text-to-Image Diffusion Models</a><br>
    Brian Nlong Zhao, Yuhang Xiao, Jiashu Xu, Xinyang Jiang, Yifan Yang, Dongsheng Li, Laurent Itti, Vibhav Vineet, Yunhao Ge </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2312.14216">Paper</a>]
    </p>
  </li>
	
  <li>
    <a href="https://arxiv.org/pdf/2501.04155?">MM-GEN: Enhancing Task Performance Through Targeted Multimodal Data Curation</a><br>
    Siddharth Joshi, Besmira Nushi, Vidhisha Balachandran, Varun Chandrasekaran, Vibhav Vineet, Neel Joshi, Baharan Mirzasoleiman </b>.<br>
    <b>ArXiv</b>, 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2501.04155?">Paper</a>]
    </p>
  </li>  
  
  <li>
    <a href="https://arxiv.org/pdf/2305.18583">Controllable Text-to-Image Generation with GPT-4</a><br>
    Tianjun Zhang, Yi Zhang, Vibhav Vineet, Neel Joshi, Xin Wang </b>.<br>
    <em>arXiv</em>, 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2305.18583">Paper</a>][<a href="https://github.com/tianjunz/Control-GPT">Project page</a>]
    </p>
  </li>


  <li>
    <a href="https://arxiv.org/pdf/2106.03805">3db: A framework for debugging computer vision models</a><br>
    Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, Aleksander Madry</b>.<br>
    <b>NeurIPS</b>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2106.03805">Paper</a>][<a href="https://github.com/3db/3db">Project Page with Code</a>]
    </p>
  </li>


  <li>
    <a href="https://arxiv.org/pdf/2207.11368">Neural-Sim: Learning to Generate Training Data with NeRF</a><br>
    Yunhao Ge, Harkirat Behl, Jiashu Xu, Suriya Gunasekar, Neel Joshi, Yale Song, Xin Wang, Laurent Itti, Vibhav Vineet  </b>.<br>
    <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2207.11368">Paper</a>][<a href="https://github.com/gyhandy/Neural-Sim-NeRF">Code & Dataset</a>]
    </p>
  </li>      


  <li>
    <a href="https://arxiv.org/pdf/2212.10015">Benchmarking Spatial Reasoning Abilities of Text-to-Image Generative Models</a><br>
    Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric Horvitz, Ece Kamar, Chitta Baral, Yezhou Yang</b>.<br>
    <b>ArXiv</b>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2212.10015">Paper</a>][<a href="https://github.com/microsoft/VISOR">Project Page with Code</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2206.09592">DALL-E for Detection: Language-driven Context Image Synthesis for Object Detection</a><br>
    Yunhao Ge, Jiashu Xu, Brian Nlong Zhao, Laurent Itti, Vibhav Vineet</b>.<br>
    <em>arXiv preprint arXiv:2206.09592</em> (<b>Preprint</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2206.09592">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2203.10488.pdf">Inferring Articulated Rigid Body Dynamics from RGBD Video</a><br>
    Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav S Sukhatme</b>.<br>
    <em>International Conference on Intelligent Robots and Systems</em> (<b>IROS</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2203.10488.pdf">Paper</a>][<a href="https://eric-heiden.github.io/video2sim/">VideoSim Code & Data</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2008.08424">AutoSimulate:(Quickly) Learning Synthetic Data Generation</a><br>
    Harkirat Singh Behl, Atılım Güneș Baydin, Ran Gal, Philip HS Torr, Vibhav Vineet</b>.<br>
    <em>    European Conference on Computer Vision  </em> (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2008.08424">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1608.02192">Playing for data: Ground truth from computer games</a><br>
    Stephan R Richter, Vibhav Vineet, Stefan Roth, Vladlen Koltun</b>.<br>
    <em> European conference on computer vision </em> (<b>ECCV</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://link.springer.com/chapter/10.1007/978-3-319-46475-6_7">Paper</a>][<a href="https://download.visinf.tu-darmstadt.de/data/from_games/">Data</a>]
    </p>
  </li>


  <li>
    <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Feature space optimization for semantic video segmentation</a><br>
    Abhijit Kundu, Vibhav Vineet, Vladlen Koltun</b>.<br>
    <em> Conference on computer vision and pattern recognition </em> (<b>CVPR</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Paper</a>]
    </p>
  </li>


  <li>
    <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: Interactive 3d labeling and learning at your fingertips</a><br>
    Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, David Kim, Jamie Shotton, Pushmeet Kohli, Matthias Nießner, Antonio Criminisi, Shahram Izadi, Philip Torr</b>.<br>
    <em> ACM Transactions on Graphics </em> (<b>TOG</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Paper</a>]
    </p>
  </li>

    <li>
    <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: Interactive 3d labeling and learning at your fingertips</a><br>
    Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, David Kim, Jamie Shotton, Pushmeet Kohli, Matthias Nießner, Antonio Criminisi, Shahram Izadi, Philip Torr</b>.<br>
    <em> ACM Transactions on Graphics </em> (<b>TOG</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">The semantic paintbrush: Interactive 3d mapping and recognition in large outdoor spaces</a><br>
    Ondrej Miksik, Vibhav Vineet, Morten Lidegaard, Ram Prasaath, Matthias Nießner, Stuart Golodetz, Stephen L Hicks, Patrick Pérez, Shahram Izadi, Philip HS Torr</b>.<br>
    <em> ACM Conference on Human Factors in Computing Systems </em> (<b>CHI</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.735.3569&rep=rep1&type=pdf">Paper</a>]
    </p>
  </li>




</ul>



</ul>
</div>


<div id="footer">
  <div id="footer-text"></div>
</div>

	<center>Adapted from  <a href="https://hszhao.github.io/"> This page </a> | Last updated: 04/13/2025</center>

</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
