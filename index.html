
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Vibhav Vineet"> 
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Vibhav Vineet</title>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
</script>
</head>

<body>

<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#index">Home</a>
        <a href="publication.html">Publication</a>
        <a href="interns.html">Interns</a>
    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                <h1>Vibhav Vineet</h1>
        </div>
        <p>
          Principal Researcher <!-- in <a href="https://www.microsoft.com/en-us/research/group/vision/"> Computer Vision Group </a> --> </br> 
          <!-- Affiliated to <a href="https://www.microsoft.com/en-us/research/group/robot-learning-group/"> Robot Learning Group </a> </br> -->
          Microsoft Research</br>
          Redmond, WA</br>
          Email: firstname[dot]lastname[at]microsoft[dot]com</br>
        
        </p>
        <p>
          <a href="http://scholar.google.com/citations?user=E_UlAVQAAAAJ&hl=en">Google Scholar </a> , &nbsp
          <a href="http://dblp.uni-trier.de/pers/hd/v/Vineet:Vibhav"> DBLP </a>
        </p>
      </td>
      <td><img src="images/vibhav.png" border="0" height="250"></br></td>
    <tr>
  </tbody>
</table>

<h2>Research</h2>
<p>
  <div style="text-align:justify">My research interests are in computer vision, machine learning, and human-AI interactions. My ongoing research is focused on the development of models that utilize multi-modal data to enhance AI systems' ability to perceive and reason about the real-world environments of human users. This advancement will ultimately help AI systems to seamlessly interact and collaborate with humans, accomplishing tasks within the real world efficiently. <br>
	  Topics of interest. 1) Multi-modal robustness analysis and reasoning. 2) Video understanding and generation. 3) Embodied AI.

<br> <br>

<em> <strong>If you are interested in research collaborations or doing research internship at MSR Redmond, please contact me. </strong> </em>

  </div>
</p>



<div id="Recent and Selected Publications">
<h2>Recent and Selected Publications </h2>


<ul>

	   <li>
    <a href="">Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead</a><br>
    Vidhisha Balachandran, Jingya Chen, Lingjiao Chen, Shivam Garg, Neel Joshi, Yash Lara, John Langford, Besmira Nushi, Vibhav Vineet, Yue Wu, Safoora Yousefi </b>.<br>    
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2504.00294">Paper</a>]
    </p>
  </li>
  
     <li>
    <a href="">HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding</a><br>
    Shehreen Azad, Vibhav Vineet, Yogesh Singh Rawat  </b>.<br>
    <em>Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2503.08585?">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">Unearthing Skill-Level Insights For Under Sstanding Trade-Offs Of Foundation Models</a><br>
    Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet  </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2312.14216">Paper</a>]
    </p>
  </li>

    <li>
    <a href="">DreamDistribution: Prompt Distribution Learning for Text-to-Image Diffusion Models</a><br>
    Brian Nlong Zhao, Yuhang Xiao, Jiashu Xu, Xinyang Jiang, Yifan Yang, Dongsheng Li, Laurent Itti, Vibhav Vineet, Yunhao Ge </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2410.13826">Paper</a>]
    </p>
  </li>
	
  
  <li>
    <a href="">Controllable Text-to-Image Generation with GPT-4</a><br>
    Tianjun Zhang, Yi Zhang, Vibhav Vineet, Neel Joshi, Xin Wang </b>.<br>
    <em>arXiv</em>, 2023.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>


  <li>
    <a href="">3db: A framework for debugging computer vision models</a><br>
    Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, Aleksander Madry </b>.<br>
    <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>


  <li>
    <a href="">Neural-Sim: Learning to Generate Training Data with NeRF</a><br>
    Yunhao Ge, Harkirat Behl, Jiashu Xu, Suriya Gunasekar, Neel Joshi, Yale Song, Xin Wang, Laurent Itti, Vibhav Vineet  </b>.<br>
    <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>     


  <li>
    <a href="">Benchmarking spatial relationships in text-to-image generation</a><br>
    Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric Horvitz, Ece Kamar, Chitta Baral, Yezhou Yang </b>.<br>
    <em>arXiv</em>, 2023.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">Dall-e for detection: Language-driven context image synthesis for object detection</a><br>
    Yunhao Ge, Jiashu Xu, Brian Nlong Zhao, Laurent Itti, Vibhav Vineet </b>.<br>
    <em>arXiv</em>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">Learning Articulated Rigid Body Dynamics Simulations From Video</a><br>
    Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav Sukhatme </b>.<br>
    <em>ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality</em>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">AutoSimulate:(Quickly) Learning Synthetic Data Generation</a><br>
    Harkirat Singh Behl, Atılım Güneș Baydin, Ran Gal, Philip HS Torr, Vibhav Vineet</b>.<br>
    <em>    European Conference on Computer Vision  </em> (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://www.microsoft.com/en-us/research/uploads/prod/2020/08/autosimulate_eccv20.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="">Playing for data: Ground truth from computer games</a><br>
    Stephan R Richter, Vibhav Vineet, Stefan Roth, Vladlen Koltun</b>.<br>
    <em> European conference on computer vision </em> (<b>ECCV</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://link.springer.com/chapter/10.1007/978-3-319-46475-6_7">Paper</a>]
    </p>
  </li>


  <li>
    <a href="">Feature space optimization for semantic video segmentation</a><br>
    Abhijit Kundu, Vibhav Vineet, Vladlen Koltun</b>.<br>
    <em> Conference on computer vision and pattern recognition </em> (<b>CVPR</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Paper</a>]
    </p>
  </li>


  <li>
    <a href="">Semanticpaint: Interactive 3d labeling and learning at your fingertips</a><br>
    Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, David Kim, Jamie Shotton, Pushmeet Kohli, Matthias Nießner, Antonio Criminisi, Shahram Izadi, Philip Torr</b>.<br>
    <em> ACM Transactions on Graphics </em> (<b>TOG</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Paper</a>]
    </p>
  </li>


  <li>
    <a href="">The semantic paintbrush: Interactive 3d mapping and recognition in large outdoor spaces</a><br>
    Ondrej Miksik, Vibhav Vineet, Morten Lidegaard, Ram Prasaath, Matthias Nießner, Stuart Golodetz, Stephen L Hicks, Patrick Pérez, Shahram Izadi, Philip HS Torr</b>.<br>
    <em> ACM Conference on Human Factors in Computing Systems </em> (<b>CHI</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.735.3569&rep=rep1&type=pdf">Paper</a>]
    </p>
  </li>




</ul>



</ul>
</div>


<div id="footer">
  <div id="footer-text"></div>
</div>

	<center>Adapted from  <a href="https://hszhao.github.io/"> This page </a> | Last updated: 04/01/2022</center>

</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
