<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Vibhav Vineet"> 
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Vibhav Vineet</title>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-87320911-1', 'auto');  
</script>
</head>

<body>

<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="index.html">Home</a>
        <a href="#publication">Publication</a>
        <a href="interns.html">Interns</a>
    </div>
</nav>


<div id="Publication">
<h2>Publication </h2>

Complete updated list available on <a href="https://scholar.google.com/citations?hl=en&user=E_UlAVQAAAAJ&view_op=list_works&sortby=pubdate"> Google Scholar</a>. 
<br> <br>

<ul>


  <li>
    <a href="https://arxiv.org/pdf/2504.21318?">Phi-4-reasoning technical report</a><br>
    <!--  Abdin, et.al., </b>.<br> -->
    <b>ArXiv</b>, 2025.</br>  
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2504.21318?">Paper</a>] [<a href="https://huggingface.co/microsoft/Phi-4-reasoning">HF model</a>] 
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2504.00294">Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead</a><br>
    Vidhisha Balachandran, Jingya Chen, Lingjiao Chen, Shivam Garg, Neel Joshi, Yash Lara, John Langford, Besmira Nushi, Vibhav Vineet, Yue Wu, Safoora Yousefi </b>.<br>
    <b>ArXiv</b>, 2025.</br>  
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2504.00294">Paper</a>] [<a href="https://github.com/microsoft/eureka-ml-insights">Eureka</a>]
    </p>
  </li>
  
     <li>
    <a href="https://arxiv.org/pdf/2503.08585?">HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding</a><br>
    Shehreen Azad, Vibhav Vineet, Yogesh Singh Rawat  </b>.<br>
    <em>Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2503.08585?">Paper</a>] [<a href="https://sacrcv.github.io/HierarQ-website/">Project Page</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2410.13826">Unearthing Skill-Level Insights For Under Sstanding Trade-Offs Of Foundation Models</a><br>
    Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet  </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2410.13826">Paper</a>]
    </p>
  </li>

    <li>
    <a href="https://arxiv.org/pdf/2312.14216">DreamDistribution: Prompt Distribution Learning for Text-to-Image Diffusion Models</a><br>
    Brian Nlong Zhao, Yuhang Xiao, Jiashu Xu, Xinyang Jiang, Yifan Yang, Dongsheng Li, Laurent Itti, Vibhav Vineet, Yunhao Ge </b>.<br>
    <em>The Thirteenth International Conference on Learning Representations</em> (<b>ICLR</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2312.14216">Paper</a>]
    </p>
  </li>
  
  <li>
    <a href="https://arxiv.org/pdf/2406.10834?">Exposing the Achilles’ Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning</a><br>
    Joykirat Singh, Akshay Nambi, Vibhav Vineet </b>.<br>
    <em>The 63rd Annual Meeting of the Association for Computational Linguistics</em> (<b>ACL</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2406.10834?">Paper</a>]
    </p>
  </li>
  
  <li>
    <a href="https://arxiv.org/pdf/2505.01578">Grounding Task Assistance with Multimodal Cues from a Single Demonstration</a><br>
    Gabriel Herbert Sarch, Balasaravanan Thoravi Kumaravel, Sahithya Ravi, Vibhav Vineet, Andrew D Wilson </b>.<br>
    <em>The 63rd Annual Meeting of the Association for Computational Linguistics</em> (<b>ACL</b>), 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2505.01578">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2501.04155?">MM-GEN: Enhancing Task Performance Through Targeted Multimodal Data Curation</a><br>
    Siddharth Joshi, Besmira Nushi, Vidhisha Balachandran, Varun Chandrasekaran, Vibhav Vineet, Neel Joshi, Baharan Mirzasoleiman </b>.<br>
    <b>ArXiv</b>, 2025.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2501.04155?">Paper</a>]
    </p>
  </li>


  <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/89cc5e613d34f90de90c21e996e60b30-Paper-Conference.pdf">Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models</a><br>
    Jiayu Wang, Yifei Ming, Zhenmei Shi, Vibhav Vineet, Xin Wang, Yixuan Li, Neel Joshi  </b>.<br>
    <em>Neural Information Processing System</em> (<b>NeurIPS</b>), 2024.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/89cc5e613d34f90de90c21e996e60b30-Paper-Conference.pdf">Paper</a>] [<a href="https://github.com/jiayuww/SpatialEval">Code & Data</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Jain_PEEKABOO_Interactive_Video_Generation_via_Masked-Diffusion_CVPR_2024_paper.pdf">PEEKABOO: Interactive Video Generation via Masked-Diffusion</a><br>
    Yash Jain, Anshul Nasery, Vibhav Vineet, Harkirat Behl  </b>.<br>
    <em>Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Jain_PEEKABOO_Interactive_Video_Generation_via_Masked-Diffusion_CVPR_2024_paper.pdf">Paper</a>]
    </p>
  </li>

  
   <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/dc192b3eeffebba21bd1d82f6752b84b-Paper-Conference.pdf">DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets</a><br>
    Yash Jain, Harkirat Behl, Zsolt Kira, Vibhav Vineet  </b>.<br>
    <em>Neural Information Processing System</em> (<b>NeurIPS</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/dc192b3eeffebba21bd1d82f6752b84b-Paper-Conference.pdf">Paper</a>] [<a href="https://github.com/jinga-lala/DAMEX">Code</a>]
    </p>
  </li>

  <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/cef53466b62aebbcf8aa2210a89b33a1-Paper-Datasets_and_Benchmarks.pdf">Revealing the unseen: Benchmarking video action recognition under occlusion</a><br>
    Shresth Grover, Vibhav Vineet, Yogesh Singh Rawat  </b>.<br>
    <em>Neural Information Processing System Dataset and Benchmark track</em> (<b>NeurIPS</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/cef53466b62aebbcf8aa2210a89b33a1-Paper-Datasets_and_Benchmarks.pdf">Paper</a>] [<a href="https://shroglck.github.io/rev_unseen/">Project Page with Data</a>]
    </p>
  </li>

  <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/b3640c2d3e58f716c67066046318db0f-Paper-Datasets_and_Benchmarks.pdf">On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes</a><br>
    Rajat Modi, Vibhav Vineet, Yogesh Singh Rawat  </b>.<br>
    <em>Neural Information Processing System Dataset and Benchmark track</em> (<b>NeurIPS</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/b3640c2d3e58f716c67066046318db0f-Paper-Datasets_and_Benchmarks.pdf">Paper</a>] [<a href="https://github.com/rajatmodi62/OccludedActionBenchmark">Code & Data</a>]
    </p>
  </li>
  
  <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf">Efficiently Robustify Pre-Trained Models</a><br>
    Nishant Jain, Harkirat Behl, Yogesh Rawat, Vibhav Vineet  </b>.<br>
    <em>International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf">Paper</a>]
    </p>
  </li>


  <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf">YCB Digital Twins for Sim2Real Analysis</a><br>
    Sruthi Sudhakar, Jon Hanzelka, Josh Bobillot, Tanmay Randhavane, Pedro Urbina, Neel Joshi, Vibhav Vineet  </b>.<br>
    <em>International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2306.09278">Robustness Analysis on Foundational Segmentation Models</a><br>
    Madeline Chantry Schiappa, Sachidanand VS, Yunhao Ge, Ondrej Miksik, Yogesh S Rawat, Vibhav Vineet </b>.<br>
    <em>arXiv</em>, 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2306.09278">Paper</a>] [<a href="https://github.com/DeepLearningRobustnessStudies/SegmetationRobustness">Code & Dataset</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2305.18583">Controllable Text-to-Image Generation with GPT-4</a><br>
    Tianjun Zhang, Yi Zhang, Vibhav Vineet, Neel Joshi, Xin Wang </b>.<br>
    <em>arXiv</em>, 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2305.18583">Paper</a>][<a href="https://github.com/tianjunz/Control-GPT">Project page</a>]
    </p>
  </li>

  <li>
    <a href="https://proceedings.mlr.press/v229/thomas23a/thomas23a.pdf">PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining</a><br>
    Garrett Thomas, Ching-An Cheng, Ricky Loynd, Vibhav Vineet, Mihai Jalobeanu, Andrey Kolobov </b>.<br>
    <em> 7th Conference on Robot Learning</em> (<b>CoRL</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.mlr.press/v229/thomas23a/thomas23a.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Schiappa_A_Large-Scale_Robustness_Analysis_of_Video_Action_Recognition_Models_CVPR_2023_paper.pdf">A Large-Scale Robustness Analysis of Video Action Recognition Models</a><br>
    Madeline Chantry Schiappa,  Naman Biyani, Prudvi Kamtam, Shruti Vyas,  Hamid Palangi, Vibhav Vineet, Yogesh S Rawat </b>.<br>
    <em>IConference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Schiappa_A_Large-Scale_Robustness_Analysis_of_Video_Action_Recognition_Models_CVPR_2023_paper.pdf">Paper</a>]
    </p>
  </li>




  <li>
    <a href="https://arxiv.org/pdf/2207.11368">Neural-Sim: Learning to Generate Training Data with NeRF</a><br>
    Yunhao Ge, Harkirat Behl, Jiashu Xu, Suriya Gunasekar, Neel Joshi, Yale Song, Xin Wang, Laurent Itti, Vibhav Vineet  </b>.<br>
    <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2207.11368">Paper</a>][<a href="https://github.com/gyhandy/Neural-Sim-NeRF">Code & Dataset</a>]
    </p>
  </li>     
  
  <li>
    <a href="https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870299.pdf">MTFormer: Multi-Task Learning via Transformer and Cross-Task Reasoning</a><br>
    Xiaogang Xu, Hengshuang Zhao, Vibhav Vineet, Ser-Nam Lim, Antonio Torralba </b>.<br>
    <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870299.pdf">Paper</a>]
    </p>
  </li>     

  <li>
    <a href="https://openaccess.thecvf.com/content/WACV2023/papers/LaBonte_Scaling_Novel_Object_Detection_With_Weakly_Supervised_Detection_Transformers_WACV_2023_paper.pdf">Scaling Novel Object Detection with Weakly Supervised Detection Transformers</a><br>
    Tyler LaBonte, Yale Song, Xin Wang, Vibhav Vineet, Neel Joshi </b>.<br>
    <em>IEEE/CVF winter conference on applications of computer vision</em> (<b>WACV</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/WACV2023/papers/LaBonte_Scaling_Novel_Object_Detection_With_Weakly_Supervised_Detection_Transformers_WACV_2023_paper.pdf">Paper</a>]
    </p>
  </li>   
  
  <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/de6ff07cbd222c10d694c2b2f732aceb-Paper-Datasets_and_Benchmarks.pdf">Multi-Modal Robustness Analysis Against Language And Visual Perturbations</a><br>
    Madeline C. Schiappa, Shruti Vyas, Hamid Palangi, Yogesh Rawat, Vibhav Vineet </b>.<br>
    <b>NeurIPS dataset and benchmark track</b>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/de6ff07cbd222c10d694c2b2f732aceb-Paper-Datasets_and_Benchmarks.pdf">Paper</a>]
    </p>
  </li>    
  
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Schiappa_A_Large-Scale_Robustness_Analysis_of_Video_Action_Recognition_Models_CVPR_2023_paper.pdf">Large-scale Robustness Analysis of Video Action Recognition Models</a><br>
    Madeline C Schiappa, Naman Biyani, Shruti Vyas, Hamid Palangi, Vibhav Vineet, Yogesh Rawat</b>.<br>
    <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2023.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Schiappa_A_Large-Scale_Robustness_Analysis_of_Video_Action_Recognition_Models_CVPR_2023_paper.pdf">Paper</a>]
    </p>
  </li>  
  
  <li>
    <a href="https://proceedings.mlr.press/v177/mcduff22a/mcduff22a.pdf">Causalcity: Complex simulations with agency for causal discovery and reasoning</a><br>
    Daniel McDuff, Yale Song, Jiyoung Lee, Vibhav Vineet, Sai Vemprala, Nicholas Alexander Gyde, Hadi Salman, Shuang Ma, Kwanghoon Sohn, Ashish Kapoor</b>.<br>
    <em>Conference on Causal Learning and Reasoning</em> (<b>CLeaR</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.mlr.press/v177/mcduff22a/mcduff22a.pdf">Paper</a>][<a href="https://causalcity.github.io/">Project Page</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2206.09592">DALL-E for Detection: Language-driven Context Image Synthesis for Object Detection</a><br>
    Yunhao Ge, Jiashu Xu, Brian Nlong Zhao, Laurent Itti, Vibhav Vineet</b>.<br>
    <em>arXiv preprint arXiv:2206.09592</em> (<b>Preprint</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2206.09592">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2204.08945.pdf">Missingness bias in model debugging</a><br>
    Saachi Jain, Hadi Salman, Eric Wong, Pengchuan Zhang, Vibhav Vineet, Sai Vemprala, Aleksander Madry</b>.<br>
    <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2204.08945.pdf">Paper</a>][<a href="https://github.com/madrylab/missingness">Code</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2203.15867.pdf">Image Retrieval from Contextual Descriptions</a><br>
    Benno Krojer, Vaibhav Adlakha, Vibhav Vineet, Yash Goyal, Edoardo Ponti, Siva Reddy</b>.<br>
    <em>Association for Computational Linguistics</em> (<b>ACL</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2203.15867.pdf">Paper</a>][<a href="https://github.com/McGill-NLP/imagecode">Code & Data</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2203.10488.pdf">Inferring Articulated Rigid Body Dynamics from RGBD Video</a><br>
    Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav S Sukhatme</b>.<br>
    <em>International Conference on Intelligent Robots and Systems</em> (<b>IROS</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2203.10488.pdf">Paper</a>][<a href="https://eric-heiden.github.io/video2sim/">VideoSim Code & Data</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/abs/2203.08130">One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning</a><br>
    Sharath Girish, Debadeepta Dey, Neel Joshi, Vibhav Vineet, Shital Shah, Caio Cesar Teodoro Mendes, Abhinav Shrivastava, Yale Song</b>.<br>
    <em>  arXiv:2203.08130 </em> (<b>Preprint</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/abs/2203.08130">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openreview.net/pdf?id=SY8GPHd8qe9">Learning Articulated Rigid Body Dynamics Simulations From Video</a><br>
    Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav Sukhatme</b>.<br>
    <em>  ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality </em> (<b>ICLR workshop</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://openreview.net/pdf?id=SY8GPHd8qe9">Paper</a>][<a href="https://eric-heiden.github.io/video2sim/">Code & Dataset</a>]
    </p>
  </li>

  <li>
    <a href="https://proceedings.mlr.press/v164/agia22a/agia22a.pdf">Taskography: Evaluating robot task planning over large 3D scene graphs</a><br>
    Christopher Agia, Krishna Murthy Jatavallabhula, Mohamed Khodeir, Ondrej Miksik, Vibhav Vineet, Mustafa Mukadam, Liam Paull, Florian Shkurti</b>.<br>
    <em>  Conference on Robot Learning </em> (<b>CoRL</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.mlr.press/v164/agia22a/agia22a.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.pdf">Robust contrastive learning against noisy views</a><br>
    Ching-Yao Chuang, R Devon Hjelm, Xin Wang, Vibhav Vineet, Neel Joshi, Antonio Torralba, Stefanie Jegelka, Yale Song</b>.<br>
    <em>  Conference on Computer Vision and Pattern Recognition </em> (<b>CVPR</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.pdf">Paper</a>][<a href="https://github.com/chingyaoc/RINCE">Code</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.pdf">Learning to align sequential actions in the wild</a><br>
    Weizhe Liu, Bugra Tekin, Huseyin Coskun, Vibhav Vineet, Pascal Fua, Marc Pollefeys</b>.<br>
    <em>  Conference on Computer Vision and Pattern Recognition </em> (<b>CVPR</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.pdf">Paper</a>][<a href="https://github.com/weizheliu/VAVA">Code</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2106.03805">3db: A framework for debugging computer vision models</a><br>
    Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, Aleksander Madry</b>.<br>
    <b>NeurIPS</b>, 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2106.03805">Paper</a>][<a href="https://github.com/3db/3db">Project Page with Code</a>]
    </p>
  </li>



  <li>
    <a href="https://arxiv.org/pdf/2010.10691">Prediction of object geometry from acoustic scattering using convolutional neural networks</a><br>
    Ziqi Fan, Vibhav Vineet, Chenshen Lu, TW Wu, Kyla McMullen</b>.<br>
    <em>   International Conference on Acoustics, Speech and Signal Processing  </em> (<b>ICASSP</b>), 2021.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2010.10691">Paper</a>][<a href="https://faculty.eng.ufl.edu/soundpad-lab/research/aml/">Code & Dataset</a>]
    </p>
  </li>



  <li>
    <a href="https://arxiv.org/pdf/2001.07791">Depth completion using a view-constrained deep prior</a><br>
    Pallabi Ghosh, Vibhav Vineet, Larry S Davis, Abhinav Shrivastava, Sudipta Sinha, Neel Joshi</b>.<br>
    <em>   International Conference on 3D Vision  </em> (<b>3DV</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2001.07791">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1909.06993">Learning visuomotor policies for aerial navigation using cross-modal representations</a><br>
    Rogerio Bonatti, Ratnesh Madaan, Vibhav Vineet, Sebastian Scherer, Ashish Kapoor</b>.<br>
    <em>    International Conference on Intelligent Robots and Systems  </em> (<b>IROS</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1909.06993">Paper</a>][<a href="https://github.com/microsoft/AirSim-Drone-Racing-VAE-Imitation">Code</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2209.10986">Learning to Simulate Realistic LiDARs</a><br>
    Benoit Guillard, Sai Vemprala, Jayesh K. Gupta, Ondrej Miksik, Vibhav Vineet, Pascal Fua, Ashish Kapoor</b>.<br>
    <em>    International Conference on Intelligent Robots and Systems  </em> (<b>IROS</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2209.10986">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2010.02488">RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs</a><br>
    Zhiwei Xu, Thalaiyasingam Ajanthan, Vibhav Vineet, Richard Hartley</b>.<br>
    <em>    International Conference on 3D Vision  </em> (<b>3DV</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2010.02488">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2008.08424">AutoSimulate:(Quickly) Learning Synthetic Data Generation</a><br>
    Harkirat Singh Behl, Atılım Güneș Baydin, Ran Gal, Philip HS Torr, Vibhav Vineet</b>.<br>
    <em>    European Conference on Computer Vision  </em> (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/2008.08424">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1911.01802">Fast acoustic scattering using convolutional neural networks</a><br>
    Ziqi Fan, Vibhav Vineet, Hannes Gamper, Nikunj Raghuvanshi</b>.<br>
    <em>  International Conference on Acoustics, Speech and Signal Processing  </em> (<b>ICASSP</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1911.01802">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1902.03334">Photorealistic image synthesis for object instance detection</a><br>
    Tomáš Hodaň, Vibhav Vineet, Ran Gal, Emanuel Shalev, Jon Hanzelka, Treb Connell, Pedro Urbina, Sudipta N Sinha, Brian Guenter</b>.<br>
    <em>  International conference on image processing  </em> (<b>ICIP</b>), 2019.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1902.03334">Paper</a>][<a href="https://thodan.github.io/objectsynth/">Project Page with Data</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1909.06993v1">Learning Controls Using Cross-Modal Representations: Bridging Simulation and Reality for Drone Racing</a><br>
    Rogerio Bonatti, Ratnesh Madaan, Vibhav Vineet, Sebastian Scherer, Ashish Kapoor</b>.<br>
    <em> International Conference on Intelligent Robots and Systems </em> (<b>IROS</b>), 2020.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1909.06993v1">Paper</a>]
    </p>
  </li>


  <li>
    <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/DynaVis%20-%20The%20First%20International%20Workshop%20on%20Dynamic%20Scene%20Reconstruction/Miksik_Live_Reconstruction_of_Large-Scale_Dynamic_Outdoor_Worlds_CVPRW_2019_paper.pdf">Live Reconstruction of Large-Scale Dynamic Outdoor Worlds</a><br>
    Ondrej Miksik, Vibhav Vineet</b>.<br>
    <em> Conference on Computer Vision and Pattern Recognition Workshop </em> (<b>CVPR workshop</b>), 2019.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/DynaVis%20-%20The%20First%20International%20Workshop%20on%20Dynamic%20Scene%20Reconstruction/Miksik_Live_Reconstruction_of_Large-Scale_Dynamic_Outdoor_Worlds_CVPRW_2019_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Wang_Privacy-Preserving_Action_Recognition_Using_Coded_Aperture_Videos_CVPRW_2019_paper.pdf">Privacy-preserving action recognition using coded aperture videos</a><br>
    Zihao W Wang, Vibhav Vineet, Francesco Pittaluga, Sudipta N Sinha, Oliver Cossairt, Sing Bing Kang</b>.<br>
    <em> Conference on Computer Vision and Pattern Recognition Workshop </em> (<b>CVPR workshop</b>), 2019.</br>
    <p style="margin-top:3px">
      [<a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Wang_Privacy-Preserving_Action_Recognition_Using_Coded_Aperture_Videos_CVPRW_2019_paper.pdf">Paper</a>]
    </p>
  </li>



  <li>
    <a href="https://arxiv.org/pdf/1608.02192">Playing for data: Ground truth from computer games</a><br>
    Stephan R Richter, Vibhav Vineet, Stefan Roth, Vladlen Koltun</b>.<br>
    <em> European conference on computer vision </em> (<b>ECCV</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://link.springer.com/chapter/10.1007/978-3-319-46475-6_7">Paper</a>][<a href="https://download.visinf.tu-darmstadt.de/data/from_games/">Data</a>]
    </p>
  </li>

  <li>
    <a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Ranftl_Dense_Monocular_Depth_CVPR_2016_paper.pdf">Dense monocular depth estimation in complex dynamic scenes</a><br>
    Rene Ranftl, Vibhav Vineet, Qifeng Chen, Vladlen Koltun</b>.<br>
    <em> Conference on computer vision and pattern recognition </em> (<b>CVPR</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Ranftl_Dense_Monocular_Depth_CVPR_2016_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Feature space optimization for semantic video segmentation</a><br>
    Abhijit Kundu, Vibhav Vineet, Vladlen Koltun</b>.<br>
    <em> Conference on computer vision and pattern recognition </em> (<b>CVPR</b>), 2016.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Kundu_Feature_Space_Optimization_CVPR_2016_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:0eb1b105-81f3-4a79-a503-f492994cc80a/files/ma7f445a1ec0a72207ad3cbf2d7e936f4">Struck: Structured output tracking with kernels</a><br>
    Sam Hare, Stuart Golodetz, Amir Saffari, Vibhav Vineet, Ming-Ming Cheng, Stephen L Hicks, Philip HS Torr</b>.<br>
    <em> IEEE transactions on pattern analysis and machine intelligence </em> (<b>TPAMI</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://ora.ox.ac.uk/objects/uuid:0eb1b105-81f3-4a79-a503-f492994cc80a/files/ma7f445a1ec0a72207ad3cbf2d7e936f4">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: Interactive 3d labeling and learning at your fingertips</a><br>
    Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, David Kim, Jamie Shotton, Pushmeet Kohli, Matthias Nießner, Antonio Criminisi, Shahram Izadi, Philip Torr</b>.<br>
    <em> ACM Transactions on Graphics </em> (<b>TOG</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: A framework for the interactive segmentation of 3d scenes</a><br>
    Stuart Golodetz, Michael Sapienza, Julien PC Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor A Prisacariu, Olaf Kähler, Carl Yuheng Ren, David W Murray, Shahram Izadi, Philip HS Torr</b>.<br>
    <em> arXiv preprint arXiv:1510.03727 </em> (<b>Preprint</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1510.03727">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:e38145ab-c1d7-46c6-b8df-d915697500af/files/s5d86p2079">Incremental dense multi-modal 3d scene reconstruction</a><br>
    Ondrej Miksik, Yousef Amar, Vibhav Vineet, Patrick Pérez, Philip HS Torr</b>.<br>
    <em>  International Conference on Intelligent Robots and Systems </em> (<b>IROS</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://ieeexplore.ieee.org/abstract/document/7353479">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/valentin2015semanticpaint.pdf">Semanticpaint: interactive segmentation and learning of 3d worlds</a><br>
    Stuart Golodetz, Michael Sapienza, Julien PC Valentin, Vibhav Vineet, Ming-Ming Cheng, Victor A Prisacariu, Olaf Kähler, Carl Yuheng Ren, Anurag Arnab, Stephen L Hicks, David W Murray, Shahram Izadi, Philip HS Torr</b>.<br>
    <em> ACM SIGGRAPH 2015 Emerging Technologies </em> (<b>SIGGRAPH</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.robots.ox.ac.uk/~tvg/publications/2015/a22-golodetz.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:0758dad0-6b33-40d1-bade-0cc2eb6f989a/files/m7b65fa0d7751c7be336728e6cd6e6c08">Incremental dense semantic stereo fusion for large-scale semantic scene reconstruction</a><br>
    Vibhav Vineet, Ondrej Miksik, Morten Lidegaard, Matthias Nießner, Stuart Golodetz, Victor A Prisacariu, Olaf Kähler, David W Murray, Shahram Izadi, Patrick Pérez, Philip HS Torr</b>.<br>
    <em> IEEE international conference on robotics and automation </em> (<b>ICRA</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://ora.ox.ac.uk/objects/uuid:0758dad0-6b33-40d1-bade-0cc2eb6f989a/download_file?safe_filename=vineet15icra.pdf.pdf&file_format=application%2Fpdf&type_of_work=Conference">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://d1wqtxts1xzle7.cloudfront.net/40204474/The_Semantic_Paintbrush_Interactive_3D_M20151120-5128-16yxmwd-libre.pdf?1448022033=&response-content-disposition=inline%3B+filename%3DThe_Semantic_Paintbrush_Interactive_3D_M.pdf&Expires=1752986482&Signature=IrR2WJm6mFsex~Z4BFqFqTMCucF4wvKm4ot6pYPM0EFD9S5rcuwqHfMRGi3Idb2O1y7G0Q6DfV0qgRuOEoHJzP~rhAldQm3RE6niR3Kv~Fmx6oQtIoFxtwkoWpTjnLcbvJ5XWJ1kY7bzQiOZU3mNy-O~ghKupgKBw-nEBcb~HtAOQqnvr1Kbdb3Xsc3EGXxNRNVGPhavWZ3kIjrS15OjQJw~GPsmJaAB6SAm3Q5rEldZzeEUi0NvTZmzvmjFsNFPl1NrMaJV-o8tAVEkhrD5Il~-v0SqJONZiLnJWxAyVUeboc1PtNxXnLsLEivDoGzVTF7k5IFr~TCWK17t8kw2Sg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">The semantic paintbrush: Interactive 3d mapping and recognition in large outdoor spaces</a><br>
    Ondrej Miksik, Vibhav Vineet, Morten Lidegaard, Ram Prasaath, Matthias Nießner, Stuart Golodetz, Stephen L Hicks, Patrick Pérez, Shahram Izadi, Philip HS Torr</b>.<br>
    <em> ACM Conference on Human Factors in Computing Systems </em> (<b>CHI</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.735.3569&rep=rep1&type=pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf">Conditional random fields as recurrent neural networks</a><br>
    Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip HS Torr</b>.<br>
    <em>  IEEE international conference on computer vision </em> (<b>ICCV</b>), 2015.</br>
    <p style="margin-top:3px">
      [<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:66b8c923-aa5f-4cfc-952f-b6637d88d87c/files/s1544br09s">ImageSpirit: Verbal guided image parsing</a><br>
    Ming-Ming Cheng, Shuai Zheng, Wen-Yan Lin, Vibhav Vineet, Paul Sturgess, Nigel Crook, Niloy J Mitra, Philip Torr</b>.<br>
    <em>  ACM Transactions on Graphics </em> (<b>TOG</b>), 2014.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1310.4389">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://link.springer.com/content/pdf/10.1007/978-3-642-33715-4_3.pdf">Filter-based mean-field inference for random fields with higher-order terms and product label-spaces</a><br>
    Vibhav Vineet, Jonathan Warrell, Philip HS Torr</b>.<br>
    <em>  International Journal of Computer Vision </em> (<b>IJCV</b>), 2014.</br>
    <p style="margin-top:3px">
      [<a href="https://link.springer.com/content/pdf/10.1007/978-3-642-33715-4_3.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/1403.6275">A tiered move-making algorithm for general non-submodular pairwise energies</a><br>
    Vibhav Vineet, Jonathan Warrell, Philip HS Torr</b>.<br>
    <em>  arXiv preprint arXiv:1403.6275 </em> (<b>Preprint</b>), 2014.</br>
    <p style="margin-top:3px">
      [<a href="https://arxiv.org/pdf/1403.6275">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:7c812170-fbc3-44cf-965c-206eaf72b79a/files/s00000190h">Distributed non-convex admm-inference in large-scale random fields</a><br>
    Ondrej Miksik, Vibhav Vineet, Patrick Pérez, Philip HS Torr, F Cesson Sévigné</b>.<br>
    <em>  British Machine Vision Conference </em> (<b>BMVC</b>), 2014.</br>
    <p style="margin-top:3px">
      [<a href="https://ora.ox.ac.uk/objects/uuid:7c812170-fbc3-44cf-965c-206eaf72b79a/files/s00000190h">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content_cvpr_2014/papers/Zheng_Dense_Semantic_Image_2014_CVPR_paper.pdf">Dense semantic image segmentation with objects and attributes</a><br>
    Shuai Zheng, Ming-Ming Cheng, Jonathan Warrell, Paul Sturgess, Vibhav Vineet, Carsten Rother, Philip HS Torr</b>.<br>
    <em>  IEEE conference on computer vision and pattern recognition </em> (<b>CVPR</b>), 2014.</br>
    <p style="margin-top:3px">
      [<a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Zheng_Dense_Semantic_Image_2014_CVPR_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Zheng_Dense_Semantic_Image_2014_CVPR_paper.pdf">Posefield: An efficient mean-field based method for joint estimation of human pose, segmentation, and depth</a><br>
    Vibhav Vineet, Glenn Sheasby, Jonathan Warrell, Philip HS Torr</b>.<br>
    <em>  Energy Minimization Methods in Computer Vision and Pattern Recognition </em> (<b>EMMCVPR</b>), 2013.</br>
    <p style="margin-top:3px">
      [<a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Zheng_Dense_Semantic_Image_2014_CVPR_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://proceedings.neurips.cc/paper/2013/file/8dd48d6a2e2cad213179a3992c0be53c-Paper.pdf">Higher order priors for joint intrinsic image, objects, and attributes estimation</a><br>
    Vibhav Vineet, Carsten Rother, Philip Torr</b>.<br>
    <em>  Neural Information Processing Systems </em> (<b>NIPS</b>), 2013.</br>
    <p style="margin-top:3px">
      [<a href="https://proceedings.neurips.cc/paper/2013/file/8dd48d6a2e2cad213179a3992c0be53c-Paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content_iccv_2013/papers/Cheng_Efficient_Salient_Region_2013_ICCV_paper.pdf">Efficient salient region detection with soft image abstraction</a><br>
    Ming-Ming Cheng, Jonathan Warrell, Wen-Yan Lin, Shuai Zheng, Vibhav Vineet, Nigel Crook</b>.<br>
    <em>   International Conference on Computer vision </em> (<b>ICCV</b>), 2013.</br>
    <p style="margin-top:3px">
      [<a href="https://openaccess.thecvf.com/content_iccv_2013/papers/Cheng_Efficient_Salient_Region_2013_ICCV_paper.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://ora.ox.ac.uk/objects/uuid:21f87a1d-cb55-4cd0-ac54-465d3b625030/files/s1544br108">Improved Initialization and Gaussian Mixture Pairwise Terms for Dense Random Fields with Mean-field Inference.</a><br>
    Vibhav Vineet, Jonathan Warrell, Paul Sturgess, Philip HS Torr</b>.<br>
    <em>   BMVC </em> (<b>BMVC</b>), 2012.</br>
    <p style="margin-top:3px">
      [<a href="https://www.researchgate.net/profile/Paul-Sturgess/publication/268408148_Improved_Initialisation_and_Gaussian_Mixture_Pairwise_Terms_for_Dense_Random_Fields_with_Mean-field_Inference/links/5515393b0cf2b5d6a0e95c7d/Improved-Initialisation-and-Gaussian-Mixture-Pairwise-Terms-for-Dense-Random-Fields-with-Mean-field-Inference.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.academia.edu/download/76780688/cvpr2012_VineetWarrellTorr.pdf">A tiered move-making algorithm for general pairwise MRFs</a><br>
    Vibhav Vineet, Jonathan Warrell, Philip HS Torr</b>.<br>
    <em>   Conference on Computer Vision and Pattern Recognition </em> (<b>CVPR</b>), 2012.</br>
    <p style="margin-top:3px">
      [<a href="https://www.academia.edu/download/76780688/cvpr2012_VineetWarrellTorr.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.sciencedirect.com/science/article/pii/B9780123859631000071">Fast minimum spanning tree computation</a><br>
    Pawan Harish, PJ Narayanan, Vibhav Vineet, Suryakant Patidar</b>.<br>
    <em> GPU Computing Gems Jade Edition </em> (<b>GPU Gem</b>), 2012.</br>
    <p style="margin-top:3px">
      [<a href="https://www.sciencedirect.com/science/article/pii/B9780123859631000071">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.sciencedirect.com/science/article/pii/B9780123849885000292">Fast graph cuts for computer vision</a><br>
    PJ Narayanan, Vibhav Vineet, Timo Stich</b>.<br>
    <em> GPU Computing Gems Emerald Edition </em> (<b>GPU Gems</b>), 2011.</br>
    <p style="margin-top:3px">
      [<a href="https://www.sciencedirect.com/science/article/pii/B9780123849885000292">Paper</a>]
    </p>
  </li>

  <li>
    <a href="http://www.bmva.org/bmvc/2011/proceedings/paper80/paper80.pdf">Human Instance Segmentation from Video using Detector-based Conditional Random Fields.</a><br>
    Vibhav Vineet, Jonathan Warrell, Lubor Ladicky, Philip HS Torr</b>.<br>
    <em> BMVC </em> (<b>BMVC</b>), 2011.</br>
    <p style="margin-top:3px">
      [<a href="http://www.bmva.org/bmvc/2011/proceedings/paper80/paper80.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.academia.edu/download/30806775/Vibhav09Solving.pdf">Solving Multilabel MRFs Using Incremental α-Expansion on the GPUs</a><br>
    Vibhav Vineet, PJ Narayanan</b>.<br>
    <em> Asian conference on computer vision </em> (<b>ACCV</b>), 2009.</br>
    <p style="margin-top:3px">
      [<a href="https://www.academia.edu/download/30806775/Vibhav09Solving.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.536.874&rep=rep1&type=pdf">Fast minimum spanning tree for large graphs on the GPU</a><br>
    Vibhav Vineet, Pawan Harish, Suryakant Patidar, PJ Narayanan</b>.<br>
    <em> Conference on High Performance Graphics </em> (<b>HOG</b>), 2009.</br>
    <p style="margin-top:3px">
      [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.536.874&rep=rep1&type=pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://www.academia.edu/download/30806641/pawan09GraphAlgorithms.pdf">Large graph algorithms for massively multithreaded architectures</a><br>
    Pawan Harish, Vibhav Vineet, PJ Narayanan</b>.<br>
    <em> Tech. Rep. IIIT/TR/2009/74 </em> (<b>Tech Report</b>), 2009.</br>
    <p style="margin-top:3px">
      [<a href="https://www.academia.edu/download/30806641/pawan09GraphAlgorithms.pdf">Paper</a>]
    </p>
  </li>

  <li>
    <a href="https://tyler-labonte.com/labonte22cvpr.pdf">Scaling Novel Object Detection with Weakly Supervised Detection Transformers</a><br>
    Tyler LaBonte, Yale Song, Xin Wang, Vibhav Vineet, Neel Joshi</b>.<br>
    <em> arxiv </em> (<b>Preprint</b>), 2022.</br>
    <p style="margin-top:3px">
      [<a href="https://tyler-labonte.com/labonte22cvpr.pdf">Paper</a>]
    </p>
  </li>


